{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from sqlalchemy import create_engine,text \n",
    "import leafmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up DB connection parameters within PostGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the db connection parameters\n",
    "username = \"postgres\"\n",
    "password = \"12345\"\n",
    "host = \"localhost\"\n",
    "dbname = \"Buildings\"\n",
    "port = \"5432\"\n",
    "\n",
    "pg_connection = f\"PG:host={host} port={port} dbname={dbname} user={username} password={password}\"\n",
    "engine = create_engine(f\"postgresql://{username}:{password}@{host}:{port}/{dbname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data from CSDI Portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download gdb from CSDI Portal\n",
    "\n",
    "from fgdbDL import download_and_extract_gdb \n",
    "\n",
    "url = \"https://static.csdi.gov.hk/csdi-webpage/download/51d63757e2675874af80eef94afb6a35/fgdb\"\n",
    "\n",
    "#storage_path = \"/home/steeb/Documents/GIS/\"\n",
    "storage_path = r\"C:\\Users\\Steve_Lau\\Desktop\\LS Training\\ls_project1\"\n",
    "\n",
    "download_and_extract_gdb(url, storage_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download shp from CSDI Portal\n",
    "\n",
    "from shpDL import download_and_extract_shp\n",
    "\n",
    "url = 'https://static.csdi.gov.hk/csdi-webpage/download/0e55c533715b5da3ae0ca6e6024e90b4/shp'\n",
    "\n",
    "storage_path = \"/home/steeb/Documents/GIS/\"\n",
    "#storage_path = r\"C:\\Users\\Steve_Lau\\Desktop\\LS Training\\ls_project1\"\n",
    "\n",
    "download_and_extract_shp(url, storage_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile OZP data from CSDI Portal using WFS\n",
    "\n",
    "from ozp2pgsql import fetch_and_process_wfs_data\n",
    "\n",
    "wfs_url = 'https://www.ozp.tpb.gov.hk/arcgis/services/DATA/OZP_PLAN_CSDI/MapServer/WFSServer?request=GetCapabilities&service=WFS'\n",
    "download_dir = r\"C:\\Users\\Steve_Lau\\Downloads\\ozp\"\n",
    "postgis_conn_string = \"postgresql://{username}:{password}@{host}:{port}/{dbname}\"\n",
    "\n",
    "fetch_and_process_wfs_data(wfs_url, download_dir, postgis_conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from owslib.wfs import WebFeatureService\n",
    "from requests import Request, get\n",
    "from io import BytesIO\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# URL of the WFS service\n",
    "wfs_url = 'https://www.ozp.tpb.gov.hk/arcgis/services/DATA/OZP_PLAN_CSDI/MapServer/WFSServer?request=GetCapabilities&service=WFS'\n",
    "\n",
    "# Initialize WFS service\n",
    "wfs = WebFeatureService(url=wfs_url, version='1.1.0')\n",
    "\n",
    "# Fetch the last available layer\n",
    "layer_name = list(wfs.contents)[-1]\n",
    "\n",
    "params = dict(service='WFS', version=\"2.0.0\", request='GetFeature',\n",
    "              typeName=layer_name, outputFormat='geojson')\n",
    "\n",
    "# Parse the URL with parameters\n",
    "wfs_request_url = Request('GET', wfs_url, params=params).prepare().url\n",
    "\n",
    "# Read data from URL\n",
    "gdf_ozp_index = gpd.read_file(wfs_request_url)\n",
    "\n",
    "# Directory to store the downloaded zip files\n",
    "download_dir = r\"C:\\Users\\Steve_Lau\\Downloads\\ozp\"\n",
    "if not os.path.exists(download_dir):\n",
    "    os.makedirs(download_dir)\n",
    "\n",
    "# Open each link under the column \"GML_LINK\" and download the zip files\n",
    "for index, row in gdf_ozp_index.iterrows():\n",
    "    link = row.get('GML_LINK')\n",
    "    if link:\n",
    "        response = get(link)\n",
    "        if response.status_code == 200:\n",
    "            zip_file_path = os.path.join(download_dir, f\"{index}.zip\")\n",
    "            with open(zip_file_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Define the directory containing the zip files\n",
    "download_dir = r\"C:\\Users\\Steve_Lau\\Downloads\\ozp\"\n",
    "\n",
    "# List all zip files in the directory\n",
    "zip_files = [f for f in os.listdir(download_dir) if f.endswith('.zip')]\n",
    "\n",
    "# Initialize an empty list to hold the GeoDataFrames\n",
    "gdf_ozp = []\n",
    "\n",
    "# Loop through each zip file\n",
    "for zip_file in zip_files:\n",
    "    zip_path = os.path.join(download_dir, zip_file)\n",
    "    \n",
    "    # Open the zip file\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        # Find the full path of 'ZONE.gml' within the zip file\n",
    "        zone_gml_path = None\n",
    "        for file_name in z.namelist():\n",
    "            if file_name.endswith('ZONE.gml'):\n",
    "                zone_gml_path = file_name\n",
    "                break\n",
    "        \n",
    "        # If 'ZONE.gml' is found, extract and read it\n",
    "        if zone_gml_path:\n",
    "            # Extract 'ZONE.gml' to a temporary location\n",
    "            z.extract(zone_gml_path, download_dir)\n",
    "            \n",
    "            # Read the extracted GML file into a GeoDataFrame\n",
    "            gml_path = os.path.join(download_dir, zone_gml_path)\n",
    "            gdf = gpd.read_file(gml_path)\n",
    "            \n",
    "            # Append the GeoDataFrame to the list\n",
    "            gdf_ozp.append(gdf)\n",
    "            \n",
    "            # Remove the extracted GML file after reading\n",
    "            os.remove(gml_path)\n",
    "\n",
    "# Merge all the GeoDataFrames into a single GeoDataFrame\n",
    "gdf_merged_ozp = pd.concat(gdf_ozp, ignore_index=True)\n",
    "\n",
    "print(f\"Successfully merged {len(gdf_ozp)} GML files into one GeoDataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_merged_ozp.to_postgis(\"gdf_merged_ozp\", engine, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_merged_ozp.value_counts(\"PLAN_NO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up paths and layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths and layer name (comment out either one gdb_path when not in use)\n",
    "\n",
    "# Building Footprint database\n",
    "#blg_gdb_path = \"/home/steeb/Documents/GIS/20240509/Building_Footprint.gdb\"\n",
    "blg_gdb_path = r\"C:\\Users\\Steve_Lau\\Desktop\\LS Training\\ls_project1\\Building_Footprint.gdb\"\n",
    "\n",
    "# Lot database\n",
    "#lot_gdb_path = \"/home/steeb/Documents/GIS/LandParcel_Lot.gdb\"\n",
    "lot_gdb_path = r\"C:\\Users\\Steve_Lau\\Desktop\\LS Training\\ls_project1\\LandParcel_Lot.gdb\"\n",
    "\n",
    "# Building information and age records\n",
    "#bdbiar_shp_path = \"/home/steeb/Documents/GIS/BDBIAR.shp\"\n",
    "bdbiar_shp_path = r\"C:\\Users\\Steve_Lau\\Desktop\\LS Training\\ls_project1\\BDBIAR.shp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import into a PostgreSQL database using ogr2ogr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports Building Footprint GDB into a PostgreSQL database using ogr2ogr\n",
    "from gdb2pgsql import transfer_gdb_to_postgis\n",
    "\n",
    "transfer_gdb_to_postgis(blg_gdb_path, pg_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports Lot GDB into a PostgreSQL database using ogr2ogr\n",
    "from gdb2pgsql import transfer_gdb_to_postgis\n",
    "\n",
    "transfer_gdb_to_postgis(lot_gdb_path, pg_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports Building information and age records SHP into a PostgreSQL database using ogr2ogr\n",
    "from shp2pgsql import import_shapefile_to_postgresql\n",
    "\n",
    "import_shapefile_to_postgresql(bdbiar_shp_path, pg_connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace variable with GDB path to inspect available layers within the specified GDB\n",
    "\n",
    "from gdbList import list_layers_with_types\n",
    "\n",
    "list_layers_with_types(lot_gdb_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data from PostgreSQL database into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_op = \"OCCUPATION_PERMIT\"\n",
    "table_op_blgstr = \"OP_BUILDING_STRUCTURE\"\n",
    "table_blgstr = \"BUILDING_STRUCTURE\"\n",
    "table_blgcat = \"CT_BUILDING_CATEGORY\"\n",
    "table_bdbiar = \"BDBIAR\"\n",
    "\n",
    "sql_op = text(f\"SELECT * FROM {table_op}\")\n",
    "sql_op_blgstr = text(f\"SELECT * FROM {table_op_blgstr}\")\n",
    "sql_blstr = text(f\"SELECT * FROM {table_blgstr}\")\n",
    "sql_blgcat = text(f\"SELECT * FROM {table_blgcat}\")\n",
    "sql_bdbiar = text(f\"SELECT * FROM {table_bdbiar}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the tables into DataFrames\n",
    "df_op = pd.read_sql(sql_op, con=engine.connect())\n",
    "df_op_blgstr = pd.read_sql(sql_op_blgstr, con=engine.connect())\n",
    "df_blgcat = pd.read_sql(sql_blgcat, con=engine.connect())\n",
    "\n",
    "# Read the tables with geometry into DataFrames\n",
    "gdf_blgstr = gpd.read_postgis(sql_blstr, con=engine.connect(), geom_col=\"shape\") \n",
    "gdf_bdbiar = gpd.read_postgis(sql_bdbiar, con=engine.connect(), geom_col=\"wkb_geometry\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the \"opno\" and \"opdate\" columns from df_op\n",
    "df_op_subset = df_op[[\"opno\", \"opdate\"]]\n",
    "\n",
    "df_op_subset.opdate = pd.to_datetime(df_op_subset[\"opdate\"], utc=True)\n",
    "\n",
    "# Merge df_op_blgstr with the subset of df_op on the \"opno\" column\n",
    "df_merge_op_blgstr = pd.merge(df_op_blgstr,\n",
    "                            df_op_subset,\n",
    "                            on=\"opno\",\n",
    "                            how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the \"buildingstructureid\" and \"opdate\" columns from df_merge_op_blgstr\n",
    "df_merge_op_blgstr_subset = df_merge_op_blgstr[[\"buildingstructureid\", \"opno\", \"opdate\"]]\n",
    "\n",
    "# Merge gdf_blgstr with the subset of df_merge_op_blgstr on the \"buildingstructureid\" column\n",
    "gdf_merge_blgstr = pd.merge(gdf_blgstr,\n",
    "                df_merge_op_blgstr_subset,\n",
    "                on=\"buildingstructureid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the \"buildingstructureid\" and \"opdate\" columns from df_merge_op_blgstr\n",
    "df_blgcat_subset = df_blgcat[[\"code\",\n",
    "                              \"description\",\n",
    "                              \"note\"]]\n",
    "\n",
    "df_blgcat_subset = df_blgcat_subset.rename(columns={\"code\": \"category\",\n",
    "                                 \"description\": \"catdesc\",\n",
    "                                 \"note\": \"catnote\"})\n",
    "\n",
    "gdf_merge_blgstr.category = gdf_merge_blgstr.category.astype(\"object\").astype(\"int64\")\n",
    "\n",
    "# Merge gdf_blgstr with the subset of df_merge_op_blgstr on the \"buildingstructureid\" column\n",
    "gdf_merge_blgstr = pd.merge(gdf_merge_blgstr,\n",
    "                df_blgcat_subset,\n",
    "                on=\"category\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = pd.to_datetime('today', utc=True).normalize()\n",
    "\n",
    "gdf_merge_blgstr[\"calcdate\"] = today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_merge_blgstr['age'] = (gdf_merge_blgstr[\"calcdate\"] - gdf_merge_blgstr[\"opdate\"]) / pd.Timedelta(days=365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only relevant columns\n",
    "gdf_merge_blgstr = gdf_merge_blgstr.loc[:, (\"buildingstructureid\",\n",
    "                    \"buildingcsuid\",\n",
    "                    \"buildingstructuretype\",\n",
    "                    \"catdesc\",\n",
    "                    \"catnote\",\n",
    "                    \"status\",\n",
    "                    \"officialbuildingnameen\",\n",
    "                    \"officialbuildingnametc\",\n",
    "                    \"numabovegroundstoreys\",\n",
    "                    \"numbasementstoreys\",\n",
    "                    \"topheight\",\n",
    "                    \"baseheight\",\n",
    "                    \"opno\",\n",
    "                    \"opdate\",\n",
    "                    \"age\",\n",
    "                    \"shape\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Building structure and Building age by \"Tower\" type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_blgstr_tower = gdf_merge_blgstr[gdf_merge_blgstr.buildingstructuretype == \"T\"]\n",
    "gdf_bdbiar_tower = gdf_bdbiar[gdf_bdbiar.nsearch4_e == \"Tower\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_bdbiar_tower.to_crs(epsg=2326, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sjoin_blgstr = gpd.sjoin(gdf_blgstr_tower, gdf_bdbiar_tower, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sjoin_blgstr = gpd.sjoin_nearest(gdf_blgstr_tower, gdf_bdbiar_tower, how=\"left\", max_distance=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sjoin_blgstr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only relevant columns\n",
    "gdf_sjoin_blgstr = gdf_sjoin_blgstr.loc[:, (\"buildingstructureid\",\n",
    "                    \"buildingcsuid\",\n",
    "                    \"buildingstructuretype\",\n",
    "                    \"catdesc\",\n",
    "                    \"catnote\",\n",
    "                    \"status\",\n",
    "                    \"officialbuildingnameen\",\n",
    "                    \"officialbuildingnametc\",\n",
    "                    \"numabovegroundstoreys\",\n",
    "                    \"numbasementstoreys\",\n",
    "                    \"topheight\",\n",
    "                    \"baseheight\",\n",
    "                    \"opno\",\n",
    "                    \"opdate\",\n",
    "                    \"age\",\n",
    "                    \"address_e\",\n",
    "                    \"address_c\",\n",
    "                    \"search1_e\",\n",
    "                    \"search1_c\",\n",
    "                    \"search2_e\",\n",
    "                    \"search2_c\",\n",
    "                    \"nsearch2_e\",\n",
    "                    \"nsearch2_c\",\n",
    "                    \"nsearch3_e\",\n",
    "                    \"nsearch3_c\",\n",
    "                    \"nsearch4_e\",\n",
    "                    \"nsearch4_c\",\n",
    "                    \"nsearch5_e\",\n",
    "                    \"nsearch5_c\",\n",
    "                    \"shape\"\n",
    "                    )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sjoin_blgstr.to_postgis(\"gdf_sjoin_blgstr_10m\", engine, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_sjoin_blgstr.nsearch5_e.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geolab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
